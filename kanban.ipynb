{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "\n",
    "def timedelta_to_hours_rounded(td, precision=2):\n",
    "    return round(td.total_seconds() / 60 / 60, precision)\n",
    "\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('scratch.data.csv')\n",
    "\n",
    "# Remove empty start dates\n",
    "data_filtered = data[~data['Started'].isna()]\n",
    "# Just to be safe also remove empty end dates\n",
    "data_filtered = data_filtered[~data_filtered['Completed'].isna()]\n",
    "\n",
    "# Create the new data frame\n",
    "df = pd.DataFrame(columns=['Task', 'Start', 'Finish', 'Resource'])\n",
    "\n",
    "# Add the data\n",
    "df['Task'] = data_filtered['ID']\n",
    "df['Start'] = pd.to_datetime(data_filtered['Started'])\n",
    "df['Finish'] = pd.to_datetime(data_filtered['Completed'])\n",
    "df['Duration'] = df['Finish'] - df['Start']\n",
    "df['Resource'] = data_filtered['Assignee']\n",
    "\n",
    "# Define primary stats\n",
    "throughput = len(df)\n",
    "mean_duration = timedelta_to_hours_rounded(df['Duration'].mean())\n",
    "median_duration = timedelta_to_hours_rounded(df['Duration'].median())\n",
    "min_duration = timedelta_to_hours_rounded(df['Duration'].min())\n",
    "max_duration = timedelta_to_hours_rounded(df['Duration'].max())\n",
    "\n",
    "md(\"\"\"\n",
    "\\\\begin{{align*}}\n",
    "  \\\\textbf{{Throughput}} &= {} \\\\text{{ cards}}\\\\\\\\\n",
    "  \\\\textbf{{Mean}} &= {} \\\\text{{ hours}}\\\\\\\\\n",
    "  \\\\textbf{{Median}} &= {} \\\\text{{ hours}}\\\\\\\\\n",
    "  \\\\textbf{{Min}} &= {} \\\\text{{ hours}}\\\\\\\\\n",
    "  \\\\textbf{{Max}} &= {} \\\\text{{ hours}}\\\\\\\\\n",
    "\\\\end{{align*}}\n",
    "\"\"\".format(\n",
    "    throughput,\n",
    "    mean_duration,\n",
    "    median_duration,\n",
    "    min_duration,\n",
    "    max_duration,\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "with open('states.json') as f:\n",
    "    states_result = json.load(f)\n",
    "\n",
    "states = list()\n",
    "for state in states_result['workflowStates']['nodes']:\n",
    "    states.append(state['name'])\n",
    "\n",
    "columns = ['ID']\n",
    "for state in states:\n",
    "    columns.append(f\"{state} Start\")\n",
    "    columns.append(f\"{state} End\")\n",
    "    columns.append(f\"{state} Duration\")\n",
    "\n",
    "issue_state_dates = pd.DataFrame(columns=columns)\n",
    "\n",
    "with open('data.json') as f:\n",
    "    result = json.load(f)\n",
    "\n",
    "oldest_created_date = pd.to_datetime(\n",
    "    datetime.utcnow().strftime(\"%d/%m/%Y %H:%M:%SZ\"))\n",
    "for issue in result['issues']['nodes']:\n",
    "    issue_created_at = pd.to_datetime(issue['createdAt'])\n",
    "    if issue_created_at < oldest_created_date:\n",
    "        oldest_created_date = issue_created_at\n",
    "    row = dict()\n",
    "    row['ID'] = issue['identifier']\n",
    "    for state in states:\n",
    "        row[f\"{state} Start\"] = pd.NA\n",
    "        row[f\"{state} End\"] = pd.NA\n",
    "        row[f\"{state} Duration\"] = pd.NA\n",
    "    oldest_state = 'For Grooming'\n",
    "    oldest_state_date = pd.to_datetime(\n",
    "        datetime.utcnow().strftime(\"%d/%m/%Y %H:%M:%SZ\"))\n",
    "    for history in issue['history']['nodes']:\n",
    "        if history['fromState'] is None:\n",
    "            continue\n",
    "        row[f\"{history['fromState']['name']} End\"] = pd.to_datetime(\n",
    "            history['createdAt'])\n",
    "        row[f\"{history['toState']['name']} Start\"] = pd.to_datetime(\n",
    "            history['createdAt'])\n",
    "        if pd.to_datetime(history['createdAt']) < oldest_state_date:\n",
    "            oldest_state = history['fromState']['name']\n",
    "            oldest_state_date = pd.to_datetime(history['createdAt'])\n",
    "    row[f\"{oldest_state} Start\"] = issue_created_at\n",
    "    for state in states:\n",
    "        if row[f\"{state} Start\"] is not pd.NA and row[f\"{state} End\"] is not pd.NA:\n",
    "            row[f\"{state} Duration\"] = row[f\"{state} End\"] - \\\n",
    "                row[f\"{state} Start\"]\n",
    "    issue_state_dates.loc[len(issue_state_dates)] = row\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "state_counts = pd.DataFrame(columns=['Date'] + states + ['Total'])\n",
    "\n",
    "for day in pd.date_range(start=oldest_created_date, end=pd.to_datetime(datetime.utcnow().strftime(\"%d/%m/%Y %H:%M:%SZ\")), freq='D', normalize=True):\n",
    "    next_day = day + pd.Timedelta(days=1)\n",
    "    row = dict()\n",
    "    row['Date'] = day\n",
    "    row['Total'] = 0\n",
    "    for state in states:\n",
    "        row[state] = 0\n",
    "    oldest_possible = oldest_created_date - pd.Timedelta(days=1)\n",
    "    for index, issue in issue_state_dates.iterrows():\n",
    "        latest_state = ''\n",
    "        latest_state_date = oldest_possible\n",
    "        for state in states:\n",
    "            if issue[f\"{state} Start\"] is not pd.NA:\n",
    "                state_start = pd.to_datetime(issue[f\"{state} Start\"])\n",
    "                if state_start < next_day and state_start > latest_state_date:\n",
    "                    latest_state = state\n",
    "                    latest_state_date = state_start\n",
    "        if '' != latest_state:\n",
    "            row[latest_state] += 1\n",
    "            row['Total'] += 1\n",
    "\n",
    "    state_counts.loc[len(state_counts)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "columns = ['Date', 'Triage', 'For Grooming', 'Todo backlog', 'Todo', 'In Progress', 'In Review', 'Done', 'Canceled']\n",
    "plot_states = state_counts[columns]\n",
    "\n",
    "\n",
    "figure = plt.figure()\n",
    "ax = figure.add_subplot(1, 1, 1)\n",
    "ax.stackplot(plot_states['Date'], plot_states.drop('Date', axis=1).T, labels=columns[1:])\n",
    "ax.legend(loc='upper left')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
