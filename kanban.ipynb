{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphql import DocumentNode\n",
    "from gql import gql\n",
    "from os import environ, path\n",
    "import json\n",
    "from typing import Any, Dict\n",
    "from linear_client import LinearClient\n",
    "\n",
    "TEAM_NAME: str = 'Juristat'\n",
    "AFTER_DATE: str = '2023-03-01'\n",
    "BEFORE_DATE: str = '2023-03-31'\n",
    "\n",
    "TOKEN: str = environ.get('LINEAR_API_KEY')\n",
    "client: LinearClient = LinearClient(TOKEN)\n",
    "\n",
    "with open(path.join('queries', 'states.gql'), 'r') as file_handle:\n",
    "    states_query: DocumentNode = gql(file_handle.read())\n",
    "\n",
    "variable_values: Dict[str, Any] = {\n",
    "    'filter': {\n",
    "        'team': {\n",
    "            'name': {\n",
    "                'eq': TEAM_NAME\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "states_result: Dict[str, Any] = client.execute(\n",
    "    states_query, variable_values=variable_values)\n",
    "\n",
    "with open('states.json', 'w') as f:\n",
    "    json.dump(states_result, f)\n",
    "\n",
    "with open(path.join('queries', 'issues.gql'), 'r') as file_handle:\n",
    "    issues_query: DocumentNode = gql(file_handle.read())\n",
    "\n",
    "variable_values: Dict[str, Any] = {\n",
    "    'filter': {\n",
    "        'team': {\n",
    "            'name': {\n",
    "                'eq': TEAM_NAME\n",
    "            }\n",
    "        },\n",
    "        'createdAt': {\n",
    "            'gt': AFTER_DATE,\n",
    "            'lt': BEFORE_DATE,\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "issues_result = client.drain(\n",
    "    query=issues_query,\n",
    "    desired_path=('issues', 'nodes'),\n",
    "    page_info_path=('issues', 'pageInfo'),\n",
    "    variable_values=variable_values,\n",
    ")\n",
    "\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(issues_result, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "TIME_FORMAT = \"%d/%m/%Y %H:%M:%SZ\"\n",
    "CURRENT_NOW = pd.to_datetime(datetime.utcnow().strftime(TIME_FORMAT))\n",
    "\n",
    "# Generate a list of workflow states\n",
    "with open('states.json') as f:\n",
    "    states_result = json.load(f)\n",
    "states = list()\n",
    "for state in states_result['workflowStates']['nodes']:\n",
    "    states.append(state['name'])\n",
    "\n",
    "# Loop through issues and generate a dataframe of issue state dates\n",
    "columns = ['ID']\n",
    "for state in states:\n",
    "    columns.append(f\"{state} Start\")\n",
    "    columns.append(f\"{state} End\")\n",
    "    columns.append(f\"{state} Duration\")\n",
    "issue_state_dates = pd.DataFrame(columns=columns)\n",
    "with open('data.json') as f:\n",
    "    issues_result = json.load(f)\n",
    "oldest_created_date = CURRENT_NOW\n",
    "for issue in issues_result:\n",
    "    issue_created_at = pd.to_datetime(issue['createdAt'])\n",
    "    if issue_created_at < oldest_created_date:\n",
    "        oldest_created_date = issue_created_at\n",
    "    row = dict()\n",
    "    row['ID'] = issue['identifier']\n",
    "    for state in states:\n",
    "        row[f\"{state} Start\"] = pd.NA\n",
    "        row[f\"{state} End\"] = pd.NA\n",
    "        row[f\"{state} Duration\"] = pd.NA\n",
    "    oldest_state = 'For Grooming'\n",
    "    oldest_state_date = CURRENT_NOW\n",
    "    for history in issue['history']['nodes']:\n",
    "        if history['fromState'] is None:\n",
    "            continue\n",
    "        history_created_at = pd.to_datetime(history['createdAt'])\n",
    "        row[f\"{history['fromState']['name']} End\"] = history_created_at\n",
    "        row[f\"{history['toState']['name']} Start\"] = history_created_at\n",
    "        if history_created_at < oldest_state_date:\n",
    "            oldest_state = history['fromState']['name']\n",
    "            oldest_state_date = history_created_at\n",
    "    row[f\"{oldest_state} Start\"] = issue_created_at\n",
    "    for state in states:\n",
    "        if row[f\"{state} Start\"] is not pd.NA and row[f\"{state} End\"] is not pd.NA:\n",
    "            row[f\"{state} Duration\"] = row[f\"{state} End\"] - \\\n",
    "                row[f\"{state} Start\"]\n",
    "    issue_state_dates.loc[len(issue_state_dates)] = row\n",
    "\n",
    "# Calculate cycle time\n",
    "cycle_time_df = issue_state_dates[\n",
    "    ~issue_state_dates['Done Start'].isna() &\n",
    "    ~issue_state_dates['In Progress Start'].isna()\n",
    "]\n",
    "cycle_time_durations = cycle_time_df['Done Start'] - \\\n",
    "    cycle_time_df['In Progress Start']\n",
    "cycle_time = {\n",
    "    'mean': cycle_time_durations.mean(),\n",
    "    'median': cycle_time_durations.median(),\n",
    "    'min': cycle_time_durations.min(),\n",
    "    'max': cycle_time_durations.max(),\n",
    "}\n",
    "\n",
    "# Generate throughput off cycle time\n",
    "throughput = len(cycle_time_durations)\n",
    "\n",
    "# Calculate lead time of issues that have been committed to\n",
    "committed_lead_time_df = issue_state_dates[\n",
    "    ~issue_state_dates['Done Start'].isna() &\n",
    "    (\n",
    "        ~issue_state_dates['Todo Start'].isna() |\n",
    "        ~issue_state_dates['Todo backlog Start'].isna()\n",
    "    )\n",
    "]\n",
    "committed_lead_time_durations = pd.DataFrame(\n",
    "    columns=['Start', 'End', 'Duration'])\n",
    "committed_lead_time_durations['End'] = committed_lead_time_df['Done Start']\n",
    "committed_lead_time_durations['Start'] = committed_lead_time_df['Todo Start']\n",
    "for index, row in committed_lead_time_durations.iterrows():\n",
    "    if pd.isna(row['Start']):\n",
    "        row['Start'] = committed_lead_time_df['Todo backlog Start'][index]\n",
    "committed_lead_time_durations['Duration'] = committed_lead_time_durations['End'] - \\\n",
    "    committed_lead_time_durations['Start']\n",
    "committed_lead_time = {\n",
    "    'mean': committed_lead_time_durations['Duration'].mean(),\n",
    "    'median': committed_lead_time_durations['Duration'].median(),\n",
    "    'min': committed_lead_time_durations['Duration'].min(),\n",
    "    'max': committed_lead_time_durations['Duration'].max(),\n",
    "}\n",
    "\n",
    "# Calculate lead time of issues that have been suggested but not committed\n",
    "suggested_lead_time_df = issue_state_dates[\n",
    "    ~issue_state_dates['Done Start'].isna() & (\n",
    "        ~issue_state_dates['Triage Start'].isna() |\n",
    "        ~issue_state_dates['For Grooming Start'].isna()\n",
    "    )\n",
    "]\n",
    "suggested_lead_time_durations = pd.DataFrame(\n",
    "    columns=['Start', 'End', 'Duration'])\n",
    "suggested_lead_time_durations['End'] = suggested_lead_time_df['Done Start']\n",
    "suggested_lead_time_durations['Start'] = suggested_lead_time_df['Triage Start']\n",
    "for index, row in suggested_lead_time_durations.iterrows():\n",
    "    if pd.isna(row['Start']):\n",
    "        row['Start'] = suggested_lead_time_df['For Grooming Start'][index]\n",
    "suggested_lead_time_durations['Duration'] = suggested_lead_time_durations['End'] - \\\n",
    "    suggested_lead_time_durations['Start']\n",
    "suggested_lead_time = {\n",
    "    'mean': suggested_lead_time_durations['Duration'].mean(),\n",
    "    'median': suggested_lead_time_durations['Duration'].median(),\n",
    "    'min': suggested_lead_time_durations['Duration'].min(),\n",
    "    'max': suggested_lead_time_durations['Duration'].max(),\n",
    "}\n",
    "\n",
    "# Create dataframe of state counts per day for cumulative flow diagram\n",
    "state_counts = pd.DataFrame(columns=['Date'] + states + ['Total'])\n",
    "for day in pd.date_range(start=oldest_created_date, end=pd.to_datetime(datetime.utcnow().strftime(\"%d/%m/%Y %H:%M:%SZ\")), freq='D', normalize=True):\n",
    "    next_day = day + pd.Timedelta(days=1)\n",
    "    row = dict()\n",
    "    row['Date'] = day\n",
    "    row['Total'] = 0\n",
    "    for state in states:\n",
    "        row[state] = 0\n",
    "    oldest_possible = oldest_created_date - pd.Timedelta(days=1)\n",
    "    for index, issue in issue_state_dates.iterrows():\n",
    "        latest_state = ''\n",
    "        latest_state_date = oldest_possible\n",
    "        for state in states:\n",
    "            if issue[f\"{state} Start\"] is not pd.NA:\n",
    "                state_start = pd.to_datetime(issue[f\"{state} Start\"])\n",
    "                if state_start < next_day and state_start > latest_state_date:\n",
    "                    latest_state = state\n",
    "                    latest_state_date = state_start\n",
    "        if '' != latest_state:\n",
    "            row[latest_state] += 1\n",
    "            row['Total'] += 1\n",
    "    state_counts.loc[len(state_counts)] = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def timedelta_to_hours_rounded(td, precision=2):\n",
    "    return round(td.total_seconds() / 60 / 60, precision)\n",
    "\n",
    "def timedelta_to_days_rounded(td, precision=2):\n",
    "    return round(td.total_seconds() / 60 / 60 / 24, precision)\n",
    "\n",
    "\n",
    "columns = ['Date', 'Triage', 'For Grooming', 'Todo backlog',\n",
    "           'Todo', 'In Progress', 'In Review', 'Done', 'Canceled']\n",
    "plot_states = state_counts[columns]\n",
    "figure = plt.figure()\n",
    "ax = figure.add_subplot(1, 1, 1)\n",
    "ax.stackplot(plot_states['Date'], plot_states.drop(\n",
    "    'Date', axis=1).T, labels=columns[1:])\n",
    "ax.legend(loc='upper left')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n",
    "\n",
    "display(HTML(\"<p>For both throughput and cycle time, only cards that had a <code>In Progress</code> status are counted.</p>\"))\n",
    "\n",
    "display(HTML(f\"<p>Throughput: {throughput} cards</p>\"))\n",
    "\n",
    "display(HTML(f\"<p>Cycle time is the amount of time it takes from when a card has been started by a dev until it hits the <code>Done</code> status.</p>\"))\n",
    "cycle_time_headers = ['Cycle Time', 'Days', 'Hours']\n",
    "cycle_time_data = [\n",
    "    ['Mean', timedelta_to_days_rounded(cycle_time['mean']), timedelta_to_hours_rounded(cycle_time['mean'])],\n",
    "    ['Median', timedelta_to_days_rounded(cycle_time['median']), timedelta_to_hours_rounded(cycle_time['median'])],\n",
    "    ['Min', timedelta_to_days_rounded(cycle_time['min']), timedelta_to_hours_rounded(cycle_time['min'])],\n",
    "    ['Max', timedelta_to_days_rounded(cycle_time['max']), timedelta_to_hours_rounded(cycle_time['max'])],\n",
    "]\n",
    "cycle_time_table = tabulate(cycle_time_data, headers=cycle_time_headers, tablefmt='html')\n",
    "display(HTML(cycle_time_table))\n",
    "\n",
    "display(HTML(f\"<p>Committed lead time is the amount of time it takes from when a card has been committed to, ie it has a <code>Todo</code> or <code>Todo backlog</code> state, until it hits the <code>Done</code> status.</p>\"))\n",
    "committed_lead_time_headers = ['Committed Lead Time', 'Days', 'Hours']\n",
    "committed_lead_time_data = [\n",
    "    ['Mean', timedelta_to_days_rounded(committed_lead_time['mean']), timedelta_to_hours_rounded(committed_lead_time['mean'])],\n",
    "    ['Median', timedelta_to_days_rounded(committed_lead_time['median']), timedelta_to_hours_rounded(committed_lead_time['median'])],\n",
    "    ['Min', timedelta_to_days_rounded(committed_lead_time['min']), timedelta_to_hours_rounded(committed_lead_time['min'])],\n",
    "    ['Max', timedelta_to_days_rounded(committed_lead_time['max']), timedelta_to_hours_rounded(committed_lead_time['max'])],\n",
    "]\n",
    "committed_lead_time_table = tabulate(committed_lead_time_data, headers=committed_lead_time_headers, tablefmt='html')\n",
    "display(HTML(committed_lead_time_table))\n",
    "\n",
    "display(HTML(f\"<p>Suggested lead time is the amount of time it takes from when a card has been suggested, ie it has a <code>Triage</code> or <code>For Grooming</code> state, until it hits the <code>Done</code> status.</p>\"))\n",
    "suggested_lead_time_headers = ['Suggested Lead Time', 'Days', 'Hours']\n",
    "suggested_lead_time_data = [\n",
    "    ['Mean', timedelta_to_days_rounded(suggested_lead_time['mean']), timedelta_to_hours_rounded(suggested_lead_time['mean'])],\n",
    "    ['Median', timedelta_to_days_rounded(suggested_lead_time['median']), timedelta_to_hours_rounded(suggested_lead_time['median'])],\n",
    "    ['Min', timedelta_to_days_rounded(suggested_lead_time['min']), timedelta_to_hours_rounded(suggested_lead_time['min'])],\n",
    "    ['Max', timedelta_to_days_rounded(suggested_lead_time['max']), timedelta_to_hours_rounded(suggested_lead_time['max'])],\n",
    "]\n",
    "suggested_lead_time_table = tabulate(suggested_lead_time_data, headers=suggested_lead_time_headers, tablefmt='html')\n",
    "display(HTML(suggested_lead_time_table))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
